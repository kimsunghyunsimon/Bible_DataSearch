import streamlit as st
import pandas as pd
import json
from collections import Counter
import re

# ---------------------------------------------------------
# 1. í•œêµ­ì–´ ì¡°ì‚¬/ì–´ë¯¸ ì²˜ë¦¬ ë° ë¶ˆìš©ì–´ ë¡œì§
# ---------------------------------------------------------
SUFFIXES = [
    "í•˜ì‚¬", "í•˜ì‹œë‹ˆë¼", "í•˜ì‹œë§¤", "í•˜ë”ë¼", "í•˜ë‹ˆë¼", "í•˜ë¦¬ë¡œë‹¤", 
    "ê»˜ì„œ", "ì—ê²Œ", "ìœ¼ë¡œ", "ì—ì„œ", "í•˜ê³ ", "ì´ë‚˜", "ê¹Œì§€", "ë¶€í„°", "ì´ë¼", "ë‹ˆë¼",
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì™€", "ê³¼", "ë„", "ë¡œ", "ê»˜", "ì—¬"
]

IGNORE_STARTS = {'ì´', 'ê·¸', 'ì €', 'ë‚´', 'ë„¤', 'ë‚˜', 'ë„ˆ', 'ìš°', 'ì', 'ëˆ„'}
IGNORE_ENDS = {'ê²ƒ', 'ë“¤', 'ë“±', 'ì¤‘', 'ë¿', 'ì¯¤', 'ìœ„', 'ê°€', 'ëŠ”', 'ë„', 'ë¥¼', 'ì€'}

def normalize_word(word):
    """ì¡°ì‚¬ ìë¥´ê¸°"""
    if len(word) < 2: return word
    for suffix in SUFFIXES:
        if word.endswith(suffix):
            stem = word[:-len(suffix)]
            if len(stem) >= 1: return stem
    return word

def is_stop_pattern(word):
    """ë¶ˆìš©ì–´ í•„í„°ë§"""
    if len(word) not in [2, 3]: return False
    
    # ì‚¬ìš©ì ìš”ì²­ ì œì™¸ ë‹¨ì–´
    if "ë„ˆí¬" in word or "ê²ƒì´" in word: return True

    if word[0] in IGNORE_STARTS and word[-1] in IGNORE_ENDS: return True
    
    if word in ["ê°€ë¼ì‚¬ëŒ€", "ì´ë¥´ì‹œë˜", "ëŒ€ë‹µí•˜ì—¬", "ìˆëŠë‹ˆë¼", "í•˜ì˜€ë”ë¼", "í•˜ë”ë¼"]: return True
    return False

# ---------------------------------------------------------
# 2. ì„±ê²½ ë©”íƒ€ë°ì´í„°
# ---------------------------------------------------------
OT_BOOKS = [
    "ì°½ì„¸ê¸°", "ì¶œì• êµ½ê¸°", "ë ˆìœ„ê¸°", "ë¯¼ìˆ˜ê¸°", "ì‹ ëª…ê¸°", "ì—¬í˜¸ìˆ˜ì•„", "ì‚¬ì‚¬ê¸°", "ë£»ê¸°",
    "ì‚¬ë¬´ì—˜ìƒ", "ì‚¬ë¬´ì—˜í•˜", "ì—´ì™•ê¸°ìƒ", "ì—´ì™•ê¸°í•˜", "ì—­ëŒ€ìƒ", "ì—­ëŒ€í•˜", "ì—ìŠ¤ë¼", "ëŠí—¤ë¯¸ì•¼",
    "ì—ìŠ¤ë”", "ìš¥ê¸°", "ì‹œí¸", "ì ì–¸", "ì „ë„ì„œ", "ì•„ê°€", "ì´ì‚¬ì•¼", "ì˜ˆë ˆë¯¸ì•¼",
    "ì˜ˆë ˆë¯¸ì•¼ì• ê°€", "ì—ìŠ¤ê²”", "ë‹¤ë‹ˆì—˜", "í˜¸ì„¸ì•„", "ìš”ì—˜", "ì•„ëª¨ìŠ¤", "ì˜¤ë°”ëŒœ", "ìš”ë‚˜",
    "ë¯¸ê°€", "ë‚˜í›”", "í•˜ë°•êµ­", "ìŠ¤ë°”ëƒ", "í•™ê°œ", "ìŠ¤ê°€ë´", "ë§ë¼ê¸°"
]
NT_BOOKS = [
    "ë§ˆíƒœë³µìŒ", "ë§ˆê°€ë³µìŒ", "ëˆ„ê°€ë³µìŒ", "ìš”í•œë³µìŒ", "ì‚¬ë„í–‰ì „", "ë¡œë§ˆì„œ", "ê³ ë¦°ë„ì „ì„œ", "ê³ ë¦°ë„í›„ì„œ",
    "ê°ˆë¼ë””ì•„ì„œ", "ì—ë² ì†Œì„œ", "ë¹Œë¦½ë³´ì„œ", "ê³¨ë¡œìƒˆì„œ", "ë°ì‚´ë¡œë‹ˆê°€ì „ì„œ", "ë°ì‚´ë¡œë‹ˆê°€í›„ì„œ", "ë””ëª¨ë°ì „ì„œ", "ë””ëª¨ë°í›„ì„œ",
    "ë””ë„ì„œ", "ë¹Œë ˆëª¬ì„œ", "íˆë¸Œë¦¬ì„œ", "ì•¼ê³ ë³´ì„œ", "ë² ë“œë¡œì „ì„œ", "ë² ë“œë¡œí›„ì„œ", "ìš”í•œì¼ì„œ", "ìš”í•œì´ì„œ",
    "ìš”í•œì‚¼ì„œ", "ìœ ë‹¤ì„œ", "ìš”í•œê³„ì‹œë¡"
]
ALL_BOOKS_ORDER = OT_BOOKS + NT_BOOKS

def get_testament(book_name):
    if book_name in OT_BOOKS: return "êµ¬ì•½"
    elif book_name in NT_BOOKS: return "ì‹ ì•½"
    return "ê¸°íƒ€"

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
@st.cache_data
def load_data(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError: return pd.DataFrame()

    rows = []
    for book, chapters in data.items():
        for chapter, verses in chapters.items():
            for verse, content in verses.items():
                rows.append({
                    "book": book,
                    "chapter": int(chapter),
                    "verse": int(verse),
                    "text": content.get("text", ""),
                    "testament": get_testament(book)
                })
    if not rows: return pd.DataFrame()
    df = pd.DataFrame(rows)
    df['book'] = pd.Categorical(df['book'], categories=ALL_BOOKS_ORDER, ordered=True)
    df = df.sort_values(by=['book', 'chapter', 'verse']).reset_index(drop=True)
    return df

# ---------------------------------------------------------
# 4. ë¶„ì„ í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™”ë¨)
# ---------------------------------------------------------
def get_top_words(df, n=10):
    counter = Counter()
    
    # [ìµœì í™”] ì „ì²´ë¥¼ í•©ì¹˜ì§€ ì•Šê³ , í•œ ì¤„ì”© ì½ìœ¼ë©´ì„œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸ (ë©”ëª¨ë¦¬ ì ˆì•½)
    for text in df['text']:
        words = re.findall(r'\w+', text)
        processed_words = []
        for w in words:
            stem = normalize_word(w)
            # ë¶ˆìš©ì–´ ì²´í¬
            if not is_stop_pattern(w) and not is_stop_pattern(stem):
                if len(stem) > 1:
                    processed_words.append(stem)
        
        # í•œ êµ¬ì ˆ ì²˜ë¦¬ê°€ ëë‚˜ë©´ ë°”ë¡œ ì¹´ìš´í„°ì— ë°˜ì˜
        counter.update(processed_words)
    
    return counter.most_common(n)

def search_word_in_bible(df, keyword):
    count = 0
    results = []
    keyword = keyword.strip()
    if not keyword: return 0, []

    for _, row in df.iterrows():
        text = row['text']
        c = text.count(keyword)
        if c > 0:
            count += c
            results.append(f"[{row['book']} {row['chapter']}:{row['verse']}] {text}")
    return count, results

# ---------------------------------------------------------
# 5. UI êµ¬ì„±
# ---------------------------------------------------------
st.set_page_config(page_title="ì„±ê²½ ë°ì´í„° ë¶„ì„", layout="wide")
st.title("ğŸ“– ì„±ê²½ ë¹…ë°ì´í„° ë¶„ì„ê¸°")

df = load_data("bible_data.json")

if not df.empty:
    st.sidebar.header("ğŸ” ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •")
    scope = st.sidebar.radio("ë²”ìœ„ ì„ íƒ", ["ì„±ê²½ ì „ì²´", "êµ¬ì•½ë§Œ", "ì‹ ì•½ë§Œ", "ì±… ë³„ë¡œ ì„ íƒ"])

    target_df = df.copy()
    if scope == "êµ¬ì•½ë§Œ": target_df = df[df['testament'] == "êµ¬ì•½"]
    elif scope == "ì‹ ì•½ë§Œ": target_df = df[df['testament'] == "ì‹ ì•½"]
    elif scope == "ì±… ë³„ë¡œ ì„ íƒ":
        available_books = [b for b in ALL_BOOKS_ORDER if b in df['book'].unique()]
        sel = st.sidebar.selectbox("ì„±ê²½ì±… ì„ íƒ", available_books)
        target_df = df[df['book'] == sel]

    st.info(f"ë¶„ì„ ëŒ€ìƒ: **{scope}** ({len(target_df):,} êµ¬ì ˆ)")

    tab1, tab2 = st.tabs(["ğŸ“Š ë§ì´ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ (Top 10)", "ğŸ” ë‹¨ì–´ ì°¾ê¸°"])

    with tab1:
        st.subheader("ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 10")
        st.caption("â€» ì œì™¸ë¨: ë„ˆí¬, ê²ƒì´, ì´/ê·¸/ì €+ê²ƒ/ë“¤ ë“±")
        
        if st.button("ë¶„ì„ ì‹œì‘", key="btn_top"):
            with st.spinner("ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                top_list = get_top_words(target_df, 10)
                
                # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                top_df = pd.DataFrame(top_list, columns=["ë‹¨ì–´", "ë¹ˆë„ìˆ˜"])
                
                # [ìˆ˜ì •ë¨] ë­í‚¹ì„ 1ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì¸ë±ìŠ¤ ì¡°ì •
                top_df.index = top_df.index + 1
                
                col1, col2 = st.columns([1, 2])
                with col1: st.table(top_df)
                with col2: st.bar_chart(top_df.set_index("ë‹¨ì–´"))

    with tab2:
        st.subheader("ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê²€ìƒ‰")
        kwd = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥")
        if kwd:
            cnt, vss = search_word_in_bible(target_df, kwd)
            st.success(f"'{kwd}' í¬í•¨ ì´ **{cnt}ë²ˆ** ë“±ì¥")
            if vss:
                with st.expander("êµ¬ì ˆ ë³´ê¸°"):
                    # êµ¬ì ˆ ë¦¬ìŠ¤íŠ¸ë„ ë³´ê¸° ì¢‹ê²Œ ë²ˆí˜¸ ë§¤ê¹€ ì—†ì´ ì¶œë ¥í•˜ê±°ë‚˜ DataFrameìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥
                    # ì—¬ê¸°ì„œëŠ” ê¹”ë”í•œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ìœ ì§€
                    for v in vss: st.text(v)
