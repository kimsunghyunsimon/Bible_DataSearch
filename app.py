import streamlit as st
import pandas as pd
import json
from collections import Counter
import re

# ---------------------------------------------------------
# 1. í•œêµ­ì–´ ì¡°ì‚¬/ì–´ë¯¸ ì²˜ë¦¬ ë° ë¶ˆìš©ì–´ ë¡œì§
# ---------------------------------------------------------

SUFFIXES = [
    "í•˜ì‚¬", "í•˜ì‹œë‹ˆë¼", "í•˜ì‹œë§¤", "í•˜ë”ë¼", "í•˜ë‹ˆë¼", "í•˜ë¦¬ë¡œë‹¤", 
    "ê»˜ì„œ", "ì—ê²Œ", "ìœ¼ë¡œ", "ì—ì„œ", "í•˜ê³ ", "ì´ë‚˜", "ê¹Œì§€", "ë¶€í„°", "ì´ë¼", "ë‹ˆë¼",
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì™€", "ê³¼", "ë„", "ë¡œ", "ê»˜", "ì—¬"
]

# íŒ¨í„´ í•„í„°ë§ìš© ì§‘í•©
IGNORE_STARTS = {'ì´', 'ê·¸', 'ì €', 'ë‚´', 'ë„¤', 'ë‚˜', 'ë„ˆ', 'ìš°', 'ì', 'ëˆ„'}
IGNORE_ENDS = {'ê²ƒ', 'ë“¤', 'ë“±', 'ì¤‘', 'ë¿', 'ì¯¤', 'ìœ„', 'ê°€', 'ëŠ”', 'ë„', 'ë¥¼', 'ì€'}

def normalize_word(word):
    """ì¡°ì‚¬ ìë¥´ê¸° (ì—¬í˜¸ì™€ê»˜ì„œ -> ì—¬í˜¸ì™€)"""
    if len(word) < 2: return word
    for suffix in SUFFIXES:
        if word.endswith(suffix):
            stem = word[:-len(suffix)]
            if len(stem) >= 1: return stem
    return word

def is_stop_pattern(word):
    """
    ë¶ˆìš©ì–´ í•„í„°ë§ ë¡œì§:
    1. 2~3ê¸€ì ë‹¨ì–´ ì¤‘ íŠ¹ì • íŒ¨í„´ì´ë‚˜ ë‹¨ì–´ê°€ í¬í•¨ëœ ê²½ìš° ì œì™¸
    """
    # ê¸¸ì´ê°€ 2~3ê¸€ìê°€ ì•„ë‹ˆë©´ ì¼ë‹¨ í†µê³¼ (ê¸¸ê±°ë‚˜ ì•„ì£¼ ì§§ì€ ë‹¨ì–´ëŠ” ë³„ë„ ë¡œì§)
    if len(word) not in [2, 3]:
        return False

    # [ì¶”ê°€ëœ ë¶€ë¶„] ì‚¬ìš©ì ìš”ì²­: 'ë„ˆí¬', 'ê²ƒì´'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì œì™¸
    # ì˜ˆ: 'ë„ˆí¬', 'ë„ˆí¬ê°€', 'ê²ƒì´', 'ì´ê²ƒì´' ë“± ëª¨ë‘ ê±¸ëŸ¬ì§
    if "ë„ˆí¬" in word or "ê²ƒì´" in word:
        return True

    # ê¸°ì¡´ íŒ¨í„´ ë¡œì§: (ì´, ê·¸, ì €...) + (ê²ƒ, ë“¤, ì€...) ì¡°í•© ì œì™¸
    if word[0] in IGNORE_STARTS:
        if word[-1] in IGNORE_ENDS:
            return True

    # ìì£¼ ë‚˜ì˜¤ëŠ” ì„±ê²½ ë§íˆ¬ ì œì™¸
    if word in ["ê°€ë¼ì‚¬ëŒ€", "ì´ë¥´ì‹œë˜", "ëŒ€ë‹µí•˜ì—¬", "ìˆëŠë‹ˆë¼", "í•˜ì˜€ë”ë¼", "í•˜ë”ë¼"]:
        return True
        
    return False

# ---------------------------------------------------------
# 2. ì„±ê²½ ë©”íƒ€ë°ì´í„°
# ---------------------------------------------------------
OT_BOOKS = [
    "ì°½ì„¸ê¸°", "ì¶œì• êµ½ê¸°", "ë ˆìœ„ê¸°", "ë¯¼ìˆ˜ê¸°", "ì‹ ëª…ê¸°", "ì—¬í˜¸ìˆ˜ì•„", "ì‚¬ì‚¬ê¸°", "ë£»ê¸°",
    "ì‚¬ë¬´ì—˜ìƒ", "ì‚¬ë¬´ì—˜í•˜", "ì—´ì™•ê¸°ìƒ", "ì—´ì™•ê¸°í•˜", "ì—­ëŒ€ìƒ", "ì—­ëŒ€í•˜", "ì—ìŠ¤ë¼", "ëŠí—¤ë¯¸ì•¼",
    "ì—ìŠ¤ë”", "ìš¥ê¸°", "ì‹œí¸", "ì ì–¸", "ì „ë„ì„œ", "ì•„ê°€", "ì´ì‚¬ì•¼", "ì˜ˆë ˆë¯¸ì•¼",
    "ì˜ˆë ˆë¯¸ì•¼ì• ê°€", "ì—ìŠ¤ê²”", "ë‹¤ë‹ˆì—˜", "í˜¸ì„¸ì•„", "ìš”ì—˜", "ì•„ëª¨ìŠ¤", "ì˜¤ë°”ëŒœ", "ìš”ë‚˜",
    "ë¯¸ê°€", "ë‚˜í›”", "í•˜ë°•êµ­", "ìŠ¤ë°”ëƒ", "í•™ê°œ", "ìŠ¤ê°€ë´", "ë§ë¼ê¸°"
]
NT_BOOKS = [
    "ë§ˆíƒœë³µìŒ", "ë§ˆê°€ë³µìŒ", "ëˆ„ê°€ë³µìŒ", "ìš”í•œë³µìŒ", "ì‚¬ë„í–‰ì „", "ë¡œë§ˆì„œ", "ê³ ë¦°ë„ì „ì„œ", "ê³ ë¦°ë„í›„ì„œ",
    "ê°ˆë¼ë””ì•„ì„œ", "ì—ë² ì†Œì„œ", "ë¹Œë¦½ë³´ì„œ", "ê³¨ë¡œìƒˆì„œ", "ë°ì‚´ë¡œë‹ˆê°€ì „ì„œ", "ë°ì‚´ë¡œë‹ˆê°€í›„ì„œ", "ë””ëª¨ë°ì „ì„œ", "ë””ëª¨ë°í›„ì„œ",
    "ë””ë„ì„œ", "ë¹Œë ˆëª¬ì„œ", "íˆë¸Œë¦¬ì„œ", "ì•¼ê³ ë³´ì„œ", "ë² ë“œë¡œì „ì„œ", "ë² ë“œë¡œí›„ì„œ", "ìš”í•œì¼ì„œ", "ìš”í•œì´ì„œ",
    "ìš”í•œì‚¼ì„œ", "ìœ ë‹¤ì„œ", "ìš”í•œê³„ì‹œë¡"
]
ALL_BOOKS_ORDER = OT_BOOKS + NT_BOOKS

def get_testament(book_name):
    if book_name in OT_BOOKS: return "êµ¬ì•½"
    elif book_name in NT_BOOKS: return "ì‹ ì•½"
    return "ê¸°íƒ€"

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
@st.cache_data
def load_data(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return pd.DataFrame()

    rows = []
    for book, chapters in data.items():
        for chapter, verses in chapters.items():
            for verse, content in verses.items():
                text = content.get("text", "")
                rows.append({
                    "book": book,
                    "chapter": int(chapter),
                    "verse": int(verse),
                    "text": text,
                    "testament": get_testament(book)
                })
    if not rows: return pd.DataFrame()
    df = pd.DataFrame(rows)
    df['book'] = pd.Categorical(df['book'], categories=ALL_BOOKS_ORDER, ordered=True)
    df = df.sort_values(by=['book', 'chapter', 'verse']).reset_index(drop=True)
    return df

# ---------------------------------------------------------
# 4. ë¶„ì„ í•¨ìˆ˜
# ---------------------------------------------------------
def get_top_words(df, n=10):
    full_text = " ".join(df['text'].tolist())
    words = re.findall(r'\w+', full_text)
    
    processed_words = []
    for w in words:
        # 1. ì¡°ì‚¬ë¥¼ ë–¼ì–´ë‚´ì„œ ê¸°ë³¸í˜• ë§Œë“¤ê¸°
        stem = normalize_word(w)
        
        # 2. ë¶ˆìš©ì–´ íŒ¨í„´ ì²´í¬ (ì›ë³¸ ë‹¨ì–´ wì™€ ì˜ë¦° ë‹¨ì–´ stem ëª¨ë‘ ì²´í¬)
        # ì˜ˆ: 'ë„ˆí¬ê°€' -> stemì€ 'ë„ˆí¬' -> 'ë„ˆí¬'ê°€ íŒ¨í„´ì— ê±¸ë¦¬ë¯€ë¡œ ì œì™¸ë¨
        if not is_stop_pattern(w) and not is_stop_pattern(stem):
            if len(stem) > 1: 
                processed_words.append(stem)
    
    return Counter(processed_words).most_common(n)

def search_word_in_bible(df, keyword):
    count = 0
    results = []
    keyword = keyword.strip()
    if not keyword: return 0, []

    for _, row in df.iterrows():
        text = row['text']
        c = text.count(keyword)
        if c > 0:
            count += c
            results.append(f"[{row['book']} {row['chapter']}:{row['verse']}] {text}")
    return count, results

# ---------------------------------------------------------
# 5. UI êµ¬ì„±
# ---------------------------------------------------------
st.set_page_config(page_title="ì„±ê²½ ë°ì´í„° ë¶„ì„", layout="wide")
st.title("ğŸ“– ì„±ê²½ ë¹…ë°ì´í„° ë¶„ì„ê¸°")

df = load_data("bible_data.json")

if not df.empty:
    st.sidebar.header("ğŸ” ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •")
    scope = st.sidebar.radio("ë²”ìœ„ ì„ íƒ", ["ì„±ê²½ ì „ì²´", "êµ¬ì•½ë§Œ", "ì‹ ì•½ë§Œ", "ì±… ë³„ë¡œ ì„ íƒ"])

    target_df = df.copy()
    if scope == "êµ¬ì•½ë§Œ": target_df = df[df['testament'] == "êµ¬ì•½"]
    elif scope == "ì‹ ì•½ë§Œ": target_df = df[df['testament'] == "ì‹ ì•½"]
    elif scope == "ì±… ë³„ë¡œ ì„ íƒ":
        available_books = [b for b in ALL_BOOKS_ORDER if b in df['book'].unique()]
        sel = st.sidebar.selectbox("ì„±ê²½ì±… ì„ íƒ", available_books)
        target_df = df[df['book'] == sel]

    st.info(f"ë¶„ì„ ëŒ€ìƒ: **{scope}** ({len(target_df):,} êµ¬ì ˆ)")

    tab1, tab2 = st.tabs(["ğŸ“Š ë§ì´ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ (Top 10)", "ğŸ” ë‹¨ì–´ ì°¾ê¸°"])

    with tab1:
        st.subheader("ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 10")
        st.caption("â€» ì œì™¸ë¨: ë„ˆí¬, ê²ƒì´, ì´/ê·¸/ì €+ê²ƒ/ë“¤ ë“± (2~3ìŒì ˆ)")
        
        if st.button("ë¶„ì„ ì‹œì‘", key="btn_top"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                top_list = get_top_words(target_df, 10)
                top_df = pd.DataFrame(top_list, columns=["ë‹¨ì–´", "ë¹ˆë„ìˆ˜"])
                col1, col2 = st.columns([1, 2])
                with col1: st.table(top_df)
                with col2: st.bar_chart(top_df.set_index("ë‹¨ì–´"))

    with tab2:
        st.subheader("ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê²€ìƒ‰")
        kwd = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥")
        if kwd:
            cnt, vss = search_word_in_bible(target_df, kwd)
            st.success(f"'{kwd}' í¬í•¨ ì´ **{cnt}ë²ˆ** ë“±ì¥")
            if vss:
                with st.expander("êµ¬ì ˆ ë³´ê¸°"):
                    for v in vss: st.text(v)
