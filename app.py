import streamlit as st
import pandas as pd
import json
from collections import Counter
import re

# ---------------------------------------------------------
# 1. ì„¤ì •: ì„±ê²½ ì±… ì´ë¦„ ì—°ê²° (Alias) ë° í†µí•© ê·œì¹™
# ---------------------------------------------------------
BOOK_ALIASES = {
    "ëˆ…": "ëˆ„ê°€ë³µìŒ",
    "ë§ˆ": "ë§ˆíƒœë³µìŒ",
    "ë§‰": "ë§ˆê°€ë³µìŒ",
    "ìš”": "ìš”í•œë³µìŒ",
    "í–‰": "ì‚¬ë„í–‰ì „",
    "ë¡¬": "ë¡œë§ˆì„œ",
    "ì°½": "ì°½ì„¸ê¸°",
    "ì¶œ": "ì¶œì• êµ½ê¸°"
}

MERGE_RULES = {
    "ì´ë¥´ì‹œë˜": "ì´ë¥´ë˜",
    "ê°€ë¼ì‚¬ëŒ€": "ì´ë¥´ë˜",
    "ì‚¬ëŒë“¤": "ì‚¬ëŒ",
    "ìë“¤": "ì"
}

STOPWORDS_EXACT = {
    "ìœ„í•˜", "ê²ƒì´", "ë„ˆí¬", "ë„ˆí¬ê°€", "ë„ˆí¬ëŠ”", "ë‚´ê°€", "ë„¤ê°€",
    "ê·¸", "ì´", "ì €", "ë‚´", "ë„¤", "ë‚˜", "ë„ˆ", "ìš°ë¦¬",
    "ìˆë‹¤", "ìˆëŠ”", "ìˆì–´", "í•˜ë‹ˆ", "í•˜ë‚˜", "í•˜ë¼", "ì´ì—"
}

SUFFIXES = [
    "í•˜ì‚¬", "í•˜ì‹œë‹ˆë¼", "í•˜ì‹œë§¤", "í•˜ë”ë¼", "í•˜ë‹ˆë¼", "í•˜ë¦¬ë¡œë‹¤", 
    "ê»˜ì„œ", "ì—ê²Œ", "ìœ¼ë¡œ", "ì—ì„œ", "í•˜ê³ ", "ì´ë‚˜", "ê¹Œì§€", "ë¶€í„°", "ì´ë¼", "ë‹ˆë¼",
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì™€", "ê³¼", "ë„", "ë¡œ", "ê»˜", "ì—¬"
]

IGNORE_STARTS = {'ì´', 'ê·¸', 'ì €', 'ë‚´', 'ë„¤', 'ë‚˜', 'ë„ˆ', 'ìš°', 'ì', 'ëˆ„'}
IGNORE_ENDS = {'ê²ƒ', 'ë“¤', 'ë“±', 'ì¤‘', 'ë¿', 'ì¯¤', 'ìœ„', 'ê°€', 'ëŠ”', 'ë„', 'ë¥¼', 'ì€'}

def normalize_word(word):
    if len(word) < 2: return word
    for suffix in SUFFIXES:
        if word.endswith(suffix):
            stem = word[:-len(suffix)]
            if len(stem) >= 1: return stem
    return word

def is_stop_pattern(word):
    if len(word) not in [2, 3]: return False
    if "ë„ˆí¬" in word or "ìœ„í•˜" in word: return True
    if word[0] in IGNORE_STARTS and word[-1] in IGNORE_ENDS: return True
    return False

# ---------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ---------------------------------------------------------
OT_BOOKS = [
    "ì°½ì„¸ê¸°", "ì¶œì• êµ½ê¸°", "ë ˆìœ„ê¸°", "ë¯¼ìˆ˜ê¸°", "ì‹ ëª…ê¸°", "ì—¬í˜¸ìˆ˜ì•„", "ì‚¬ì‚¬ê¸°", "ë£»ê¸°",
    "ì‚¬ë¬´ì—˜ìƒ", "ì‚¬ë¬´ì—˜í•˜", "ì—´ì™•ê¸°ìƒ", "ì—´ì™•ê¸°í•˜", "ì—­ëŒ€ìƒ", "ì—­ëŒ€í•˜", "ì—ìŠ¤ë¼", "ëŠí—¤ë¯¸ì•¼",
    "ì—ìŠ¤ë”", "ìš¥ê¸°", "ì‹œí¸", "ì ì–¸", "ì „ë„ì„œ", "ì•„ê°€", "ì´ì‚¬ì•¼", "ì˜ˆë ˆë¯¸ì•¼",
    "ì˜ˆë ˆë¯¸ì•¼ì• ê°€", "ì—ìŠ¤ê²”", "ë‹¤ë‹ˆì—˜", "í˜¸ì„¸ì•„", "ìš”ì—˜", "ì•„ëª¨ìŠ¤", "ì˜¤ë°”ëŒœ", "ìš”ë‚˜",
    "ë¯¸ê°€", "ë‚˜í›”", "í•˜ë°•êµ­", "ìŠ¤ë°”ëƒ", "í•™ê°œ", "ìŠ¤ê°€ë´", "ë§ë¼ê¸°"
]
NT_BOOKS = [
    "ë§ˆíƒœë³µìŒ", "ë§ˆê°€ë³µìŒ", "ëˆ„ê°€ë³µìŒ", "ìš”í•œë³µìŒ", "ì‚¬ë„í–‰ì „", "ë¡œë§ˆì„œ", "ê³ ë¦°ë„ì „ì„œ", "ê³ ë¦°ë„í›„ì„œ",
    "ê°ˆë¼ë””ì•„ì„œ", "ì—ë² ì†Œì„œ", "ë¹Œë¦½ë³´ì„œ", "ê³¨ë¡œìƒˆì„œ", "ë°ì‚´ë¡œë‹ˆê°€ì „ì„œ", "ë°ì‚´ë¡œë‹ˆê°€í›„ì„œ", "ë””ëª¨ë°ì „ì„œ", "ë””ëª¨ë°í›„ì„œ",
    "ë””ë„ì„œ", "ë¹Œë ˆëª¬ì„œ", "íˆë¸Œë¦¬ì„œ", "ì•¼ê³ ë³´ì„œ", "ë² ë“œë¡œì „ì„œ", "ë² ë“œë¡œí›„ì„œ", "ìš”í•œì¼ì„œ", "ìš”í•œì´ì„œ",
    "ìš”í•œì‚¼ì„œ", "ìœ ë‹¤ì„œ", "ìš”í•œê³„ì‹œë¡"
]
ALL_BOOKS_ORDER = OT_BOOKS + NT_BOOKS

@st.cache_data
def load_data(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError: return pd.DataFrame()

    rows = []
    for book, chapters in data.items():
        normalized_book_name = BOOK_ALIASES.get(book, book)
        for chapter, verses in chapters.items():
            for verse, content in verses.items():
                rows.append({
                    "book": normalized_book_name,
                    "chapter": int(chapter),
                    "verse": int(verse),
                    "text": content.get("text", ""),
                    "testament": "êµ¬ì•½" if normalized_book_name in OT_BOOKS else ("ì‹ ì•½" if normalized_book_name in NT_BOOKS else "ê¸°íƒ€")
                })
                
    if not rows: return pd.DataFrame()
    df = pd.DataFrame(rows)
    df['book'] = pd.Categorical(df['book'], categories=ALL_BOOKS_ORDER, ordered=True)
    
    if df['book'].isnull().any():
        df = df.sort_values(by=['book', 'chapter', 'verse']).reset_index(drop=True)
    else:
        df = df.sort_values(by=['book', 'chapter', 'verse']).reset_index(drop=True)
        
    return df

# ---------------------------------------------------------
# 3. í•µì‹¬ ë¶„ì„ í•¨ìˆ˜
# ---------------------------------------------------------
def get_top_words_fast(df, n=10):
    full_text = " ".join(df['text'].tolist())
    raw_words = re.findall(r'\w+', full_text)
    raw_counter = Counter(raw_words)
    final_counter = Counter()
    
    for word, count in raw_counter.items():
        if word in MERGE_RULES:
            target_word = MERGE_RULES[word]
            final_counter[target_word] += count
            continue
        stem = normalize_word(word)
        if stem in MERGE_RULES:
            target_word = MERGE_RULES[stem]
            final_counter[target_word] += count
            continue
        if stem in STOPWORDS_EXACT or is_stop_pattern(stem) or is_stop_pattern(word):
            continue
        if len(stem) > 1:
            final_counter[stem] += count
            
    return final_counter.most_common(n)

def search_word_in_bible(df, keyword):
    keyword = keyword.strip()
    if not keyword: return 0, [], ""
    
    results = []
    if '+' in keyword:
        keywords = [k.strip() for k in keyword.split('+') if k.strip()]
        count = 0
        for _, row in df.iterrows():
            text = row['text']
            if all(k in text for k in keywords):
                count += 1
                book_name = row['book'] if pd.notna(row['book']) else "ì•Œìˆ˜ì—†ìŒ"
                results.append(f"[{book_name} {row['chapter']}:{row['verse']}] {text}")
        return count, results, "verse"
    else:
        count = 0
        for _, row in df.iterrows():
            text = row['text']
            c = text.count(keyword)
            if c > 0:
                count += c
                book_name = row['book'] if pd.notna(row['book']) else "ì•Œìˆ˜ì—†ìŒ"
                results.append(f"[{book_name} {row['chapter']}:{row['verse']}] {text}")
        return count, results, "word"

# ---------------------------------------------------------
# 4. UI êµ¬ì„±
# ---------------------------------------------------------
st.set_page_config(page_title="ì„±ê²½ ë°ì´í„° ë¶„ì„", layout="wide")
st.title("ğŸ“– ì„±ê²½ ë¹…ë°ì´í„° ë¶„ì„ê¸°")

df = load_data("bible_data.json")

if not df.empty:
    st.write("### ğŸ” ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •")
    
    scope = st.radio(
        "ë¶„ì„í•  ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
        ["ì„±ê²½ ì „ì²´", "êµ¬ì•½ë§Œ", "ì‹ ì•½ë§Œ", "ì±… ë³„ë¡œ ì„ íƒ"], 
        horizontal=True
    )

    target_df = df.copy()
    if scope == "êµ¬ì•½ë§Œ": target_df = df[df['testament'] == "êµ¬ì•½"]
    elif scope == "ì‹ ì•½ë§Œ": target_df = df[df['testament'] == "ì‹ ì•½"]
    elif scope == "ì±… ë³„ë¡œ ì„ íƒ":
        valid_books = df['book'].dropna().unique()
        available_books = [b for b in ALL_BOOKS_ORDER if b in valid_books]
        sel = st.selectbox("ì„±ê²½ì±…ì„ ì„ íƒí•˜ì„¸ìš”:", available_books)
        target_df = df[df['book'] == sel]

    st.markdown("---")
    st.info(f"ğŸ“Š í˜„ì¬ ë¶„ì„ ëŒ€ìƒ: **{scope}** (ì´ {len(target_df):,} êµ¬ì ˆ)")

    tab1, tab2 = st.tabs(["ğŸ† Top 10 ë‹¨ì–´", "ğŸ” ë‹¨ì–´ ê²€ìƒ‰"])

    with tab1:
        st.subheader("ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 10")
        st.markdown("""
        <small>â„¹ï¸ 'ì‚¬ëŒë“¤'â†’'ì‚¬ëŒ' í†µí•© / 'ì´ì—', 'ì´/ê·¸/ì €' ë“± ë¶ˆìš©ì–´ ì œì™¸</small>
        """, unsafe_allow_html=True)
        
        if st.button("ë¶„ì„ ì‹œì‘", key="btn_top", type="primary"):
            top_list = get_top_words_fast(target_df, 10)
            top_df = pd.DataFrame(top_list, columns=["ë‹¨ì–´", "ë¹ˆë„ìˆ˜"])
            top_df.index = top_df.index + 1
            st.table(top_df)

    with tab2:
        st.subheader("ë‹¨ì–´ ë¹ˆë„ìˆ˜ ë° ìƒì„¸ ê²€ìƒ‰")
        st.caption("íŒ: 'ì˜ˆìˆ˜+ì‚¬ë‘' ì²˜ëŸ¼ ì…ë ¥í•˜ë©´ ë‘ ë‹¨ì–´ê°€ ëª¨ë‘ ìˆëŠ” êµ¬ì ˆì„ ì°¾ìŠµë‹ˆë‹¤.")
        
        # [ìˆ˜ì •ë¨] ì…ë ¥ì°½ê³¼ ë²„íŠ¼ì„ ê°€ë¡œë¡œ ë°°ì¹˜ (ë¹„ìœ¨ 4:1)
        col1, col2 = st.columns([4, 1])
        
        with col1:
            # label_visibility="collapsed"ë¡œ ë¼ë²¨ì„ ìˆ¨ê²¨ì„œ ë²„íŠ¼ê³¼ ì¤„ì„ ë§ì¶¥ë‹ˆë‹¤.
            kwd = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", label_visibility="collapsed")
            
        with col2:
            # use_container_width=Trueë¡œ ë²„íŠ¼ì„ ê½‰ ì±„ì›ë‹ˆë‹¤.
            search_btn = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)

        # ì—”í„°ë¥¼ ì³¤ê±°ë‚˜(kwdê°€ ìˆì„ ë•Œ) OR ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ ì‹¤í–‰
        if kwd:
            cnt, vss, r_type = search_word_in_bible(target_df, kwd)
            
            if r_type == "verse":
                st.success(f"ì¡°ê±´ ë§Œì¡± êµ¬ì ˆ: **{cnt}ì ˆ**")
            else:
                st.success(f"ë“±ì¥ íšŸìˆ˜: **{cnt}ë²ˆ**")
            
            if vss:
                with st.expander("êµ¬ì ˆ ë³´ê¸° (í´ë¦­)", expanded=True):
                    for v in vss: st.text(v)
